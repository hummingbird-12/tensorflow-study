{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lbFmQdsZs5eW"
   },
   "outputs": [],
   "source": [
    "# ATTENTION: Please do not alter any of the provided code in the exercise. Only add your own code where indicated\n",
    "# ATTENTION: Please do not add or remove any cells in the exercise. The grader will check specific cells based on the cell position.\n",
    "# ATTENTION: Please use the provided epoch values when training.\n",
    "\n",
    "# Import all the necessary files!\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model\n",
    "from os import getcwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1xJZ5glPPCRz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"inception_v3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_188 (Conv2D)             (None, 74, 74, 32)   864         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_188 (BatchN (None, 74, 74, 32)   96          conv2d_188[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_188 (Activation)     (None, 74, 74, 32)   0           batch_normalization_188[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_189 (Conv2D)             (None, 72, 72, 32)   9216        activation_188[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_189 (BatchN (None, 72, 72, 32)   96          conv2d_189[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_189 (Activation)     (None, 72, 72, 32)   0           batch_normalization_189[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_190 (Conv2D)             (None, 72, 72, 64)   18432       activation_189[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_190 (BatchN (None, 72, 72, 64)   192         conv2d_190[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_190 (Activation)     (None, 72, 72, 64)   0           batch_normalization_190[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 35, 35, 64)   0           activation_190[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_191 (Conv2D)             (None, 35, 35, 80)   5120        max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_191 (BatchN (None, 35, 35, 80)   240         conv2d_191[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_191 (Activation)     (None, 35, 35, 80)   0           batch_normalization_191[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_192 (Conv2D)             (None, 33, 33, 192)  138240      activation_191[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_192 (BatchN (None, 33, 33, 192)  576         conv2d_192[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_192 (Activation)     (None, 33, 33, 192)  0           batch_normalization_192[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_192[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_196 (Conv2D)             (None, 16, 16, 64)   12288       max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_196 (BatchN (None, 16, 16, 64)   192         conv2d_196[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_196 (Activation)     (None, 16, 16, 64)   0           batch_normalization_196[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_194 (Conv2D)             (None, 16, 16, 48)   9216        max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_197 (Conv2D)             (None, 16, 16, 96)   55296       activation_196[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_194 (BatchN (None, 16, 16, 48)   144         conv2d_194[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_197 (BatchN (None, 16, 16, 96)   288         conv2d_197[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_194 (Activation)     (None, 16, 16, 48)   0           batch_normalization_194[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_197 (Activation)     (None, 16, 16, 96)   0           batch_normalization_197[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_18 (AveragePo (None, 16, 16, 192)  0           max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_193 (Conv2D)             (None, 16, 16, 64)   12288       max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_195 (Conv2D)             (None, 16, 16, 64)   76800       activation_194[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_198 (Conv2D)             (None, 16, 16, 96)   82944       activation_197[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_199 (Conv2D)             (None, 16, 16, 32)   6144        average_pooling2d_18[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_193 (BatchN (None, 16, 16, 64)   192         conv2d_193[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_195 (BatchN (None, 16, 16, 64)   192         conv2d_195[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_198 (BatchN (None, 16, 16, 96)   288         conv2d_198[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_199 (BatchN (None, 16, 16, 32)   96          conv2d_199[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_193 (Activation)     (None, 16, 16, 64)   0           batch_normalization_193[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_195 (Activation)     (None, 16, 16, 64)   0           batch_normalization_195[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_198 (Activation)     (None, 16, 16, 96)   0           batch_normalization_198[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_199 (Activation)     (None, 16, 16, 32)   0           batch_normalization_199[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_193[0][0]             \n",
      "                                                                 activation_195[0][0]             \n",
      "                                                                 activation_198[0][0]             \n",
      "                                                                 activation_199[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_203 (Conv2D)             (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_203 (BatchN (None, 16, 16, 64)   192         conv2d_203[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_203 (Activation)     (None, 16, 16, 64)   0           batch_normalization_203[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_201 (Conv2D)             (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_204 (Conv2D)             (None, 16, 16, 96)   55296       activation_203[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_201 (BatchN (None, 16, 16, 48)   144         conv2d_201[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_204 (BatchN (None, 16, 16, 96)   288         conv2d_204[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_201 (Activation)     (None, 16, 16, 48)   0           batch_normalization_201[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_204 (Activation)     (None, 16, 16, 96)   0           batch_normalization_204[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_19 (AveragePo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_200 (Conv2D)             (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_202 (Conv2D)             (None, 16, 16, 64)   76800       activation_201[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_205 (Conv2D)             (None, 16, 16, 96)   82944       activation_204[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_206 (Conv2D)             (None, 16, 16, 64)   16384       average_pooling2d_19[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_200 (BatchN (None, 16, 16, 64)   192         conv2d_200[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_202 (BatchN (None, 16, 16, 64)   192         conv2d_202[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_205 (BatchN (None, 16, 16, 96)   288         conv2d_205[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_206 (BatchN (None, 16, 16, 64)   192         conv2d_206[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_200 (Activation)     (None, 16, 16, 64)   0           batch_normalization_200[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_202 (Activation)     (None, 16, 16, 64)   0           batch_normalization_202[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_205 (Activation)     (None, 16, 16, 96)   0           batch_normalization_205[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_206 (Activation)     (None, 16, 16, 64)   0           batch_normalization_206[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_200[0][0]             \n",
      "                                                                 activation_202[0][0]             \n",
      "                                                                 activation_205[0][0]             \n",
      "                                                                 activation_206[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_210 (Conv2D)             (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_210 (BatchN (None, 16, 16, 64)   192         conv2d_210[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_210 (Activation)     (None, 16, 16, 64)   0           batch_normalization_210[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_208 (Conv2D)             (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_211 (Conv2D)             (None, 16, 16, 96)   55296       activation_210[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_208 (BatchN (None, 16, 16, 48)   144         conv2d_208[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_211 (BatchN (None, 16, 16, 96)   288         conv2d_211[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_208 (Activation)     (None, 16, 16, 48)   0           batch_normalization_208[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_211 (Activation)     (None, 16, 16, 96)   0           batch_normalization_211[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_20 (AveragePo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_207 (Conv2D)             (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_209 (Conv2D)             (None, 16, 16, 64)   76800       activation_208[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_212 (Conv2D)             (None, 16, 16, 96)   82944       activation_211[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_213 (Conv2D)             (None, 16, 16, 64)   18432       average_pooling2d_20[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_207 (BatchN (None, 16, 16, 64)   192         conv2d_207[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_209 (BatchN (None, 16, 16, 64)   192         conv2d_209[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_212 (BatchN (None, 16, 16, 96)   288         conv2d_212[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_213 (BatchN (None, 16, 16, 64)   192         conv2d_213[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_207 (Activation)     (None, 16, 16, 64)   0           batch_normalization_207[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_209 (Activation)     (None, 16, 16, 64)   0           batch_normalization_209[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_212 (Activation)     (None, 16, 16, 96)   0           batch_normalization_212[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_213 (Activation)     (None, 16, 16, 64)   0           batch_normalization_213[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_207[0][0]             \n",
      "                                                                 activation_209[0][0]             \n",
      "                                                                 activation_212[0][0]             \n",
      "                                                                 activation_213[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_215 (Conv2D)             (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_215 (BatchN (None, 16, 16, 64)   192         conv2d_215[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_215 (Activation)     (None, 16, 16, 64)   0           batch_normalization_215[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_216 (Conv2D)             (None, 16, 16, 96)   55296       activation_215[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_216 (BatchN (None, 16, 16, 96)   288         conv2d_216[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_216 (Activation)     (None, 16, 16, 96)   0           batch_normalization_216[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_214 (Conv2D)             (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_217 (Conv2D)             (None, 7, 7, 96)     82944       activation_216[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_214 (BatchN (None, 7, 7, 384)    1152        conv2d_214[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_217 (BatchN (None, 7, 7, 96)     288         conv2d_217[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_214 (Activation)     (None, 7, 7, 384)    0           batch_normalization_214[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_217 (Activation)     (None, 7, 7, 96)     0           batch_normalization_217[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling2D) (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_214[0][0]             \n",
      "                                                                 activation_217[0][0]             \n",
      "                                                                 max_pooling2d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_222 (Conv2D)             (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_222 (BatchN (None, 7, 7, 128)    384         conv2d_222[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_222 (Activation)     (None, 7, 7, 128)    0           batch_normalization_222[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_223 (Conv2D)             (None, 7, 7, 128)    114688      activation_222[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_223 (BatchN (None, 7, 7, 128)    384         conv2d_223[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_223 (Activation)     (None, 7, 7, 128)    0           batch_normalization_223[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_219 (Conv2D)             (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_224 (Conv2D)             (None, 7, 7, 128)    114688      activation_223[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_219 (BatchN (None, 7, 7, 128)    384         conv2d_219[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_224 (BatchN (None, 7, 7, 128)    384         conv2d_224[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_219 (Activation)     (None, 7, 7, 128)    0           batch_normalization_219[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_224 (Activation)     (None, 7, 7, 128)    0           batch_normalization_224[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_220 (Conv2D)             (None, 7, 7, 128)    114688      activation_219[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_225 (Conv2D)             (None, 7, 7, 128)    114688      activation_224[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_220 (BatchN (None, 7, 7, 128)    384         conv2d_220[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_225 (BatchN (None, 7, 7, 128)    384         conv2d_225[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_220 (Activation)     (None, 7, 7, 128)    0           batch_normalization_220[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_225 (Activation)     (None, 7, 7, 128)    0           batch_normalization_225[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_21 (AveragePo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_218 (Conv2D)             (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_221 (Conv2D)             (None, 7, 7, 192)    172032      activation_220[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_226 (Conv2D)             (None, 7, 7, 192)    172032      activation_225[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_227 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_21[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_218 (BatchN (None, 7, 7, 192)    576         conv2d_218[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_221 (BatchN (None, 7, 7, 192)    576         conv2d_221[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_226 (BatchN (None, 7, 7, 192)    576         conv2d_226[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_227 (BatchN (None, 7, 7, 192)    576         conv2d_227[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_218 (Activation)     (None, 7, 7, 192)    0           batch_normalization_218[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_221 (Activation)     (None, 7, 7, 192)    0           batch_normalization_221[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_226 (Activation)     (None, 7, 7, 192)    0           batch_normalization_226[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_227 (Activation)     (None, 7, 7, 192)    0           batch_normalization_227[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_218[0][0]             \n",
      "                                                                 activation_221[0][0]             \n",
      "                                                                 activation_226[0][0]             \n",
      "                                                                 activation_227[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_232 (Conv2D)             (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_232 (BatchN (None, 7, 7, 160)    480         conv2d_232[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_232 (Activation)     (None, 7, 7, 160)    0           batch_normalization_232[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_233 (Conv2D)             (None, 7, 7, 160)    179200      activation_232[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_233 (BatchN (None, 7, 7, 160)    480         conv2d_233[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_233 (Activation)     (None, 7, 7, 160)    0           batch_normalization_233[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_229 (Conv2D)             (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_234 (Conv2D)             (None, 7, 7, 160)    179200      activation_233[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_229 (BatchN (None, 7, 7, 160)    480         conv2d_229[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_234 (BatchN (None, 7, 7, 160)    480         conv2d_234[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_229 (Activation)     (None, 7, 7, 160)    0           batch_normalization_229[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_234 (Activation)     (None, 7, 7, 160)    0           batch_normalization_234[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_230 (Conv2D)             (None, 7, 7, 160)    179200      activation_229[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_235 (Conv2D)             (None, 7, 7, 160)    179200      activation_234[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_230 (BatchN (None, 7, 7, 160)    480         conv2d_230[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_235 (BatchN (None, 7, 7, 160)    480         conv2d_235[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_230 (Activation)     (None, 7, 7, 160)    0           batch_normalization_230[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_235 (Activation)     (None, 7, 7, 160)    0           batch_normalization_235[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_22 (AveragePo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_228 (Conv2D)             (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_231 (Conv2D)             (None, 7, 7, 192)    215040      activation_230[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_236 (Conv2D)             (None, 7, 7, 192)    215040      activation_235[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_237 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_22[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_228 (BatchN (None, 7, 7, 192)    576         conv2d_228[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_231 (BatchN (None, 7, 7, 192)    576         conv2d_231[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_236 (BatchN (None, 7, 7, 192)    576         conv2d_236[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_237 (BatchN (None, 7, 7, 192)    576         conv2d_237[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_228 (Activation)     (None, 7, 7, 192)    0           batch_normalization_228[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_231 (Activation)     (None, 7, 7, 192)    0           batch_normalization_231[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_236 (Activation)     (None, 7, 7, 192)    0           batch_normalization_236[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_237 (Activation)     (None, 7, 7, 192)    0           batch_normalization_237[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_228[0][0]             \n",
      "                                                                 activation_231[0][0]             \n",
      "                                                                 activation_236[0][0]             \n",
      "                                                                 activation_237[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_242 (Conv2D)             (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_242 (BatchN (None, 7, 7, 160)    480         conv2d_242[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_242 (Activation)     (None, 7, 7, 160)    0           batch_normalization_242[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_243 (Conv2D)             (None, 7, 7, 160)    179200      activation_242[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_243 (BatchN (None, 7, 7, 160)    480         conv2d_243[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_243 (Activation)     (None, 7, 7, 160)    0           batch_normalization_243[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_239 (Conv2D)             (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_244 (Conv2D)             (None, 7, 7, 160)    179200      activation_243[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_239 (BatchN (None, 7, 7, 160)    480         conv2d_239[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_244 (BatchN (None, 7, 7, 160)    480         conv2d_244[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_239 (Activation)     (None, 7, 7, 160)    0           batch_normalization_239[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_244 (Activation)     (None, 7, 7, 160)    0           batch_normalization_244[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_240 (Conv2D)             (None, 7, 7, 160)    179200      activation_239[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_245 (Conv2D)             (None, 7, 7, 160)    179200      activation_244[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_240 (BatchN (None, 7, 7, 160)    480         conv2d_240[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_245 (BatchN (None, 7, 7, 160)    480         conv2d_245[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_240 (Activation)     (None, 7, 7, 160)    0           batch_normalization_240[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_245 (Activation)     (None, 7, 7, 160)    0           batch_normalization_245[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_23 (AveragePo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_238 (Conv2D)             (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_241 (Conv2D)             (None, 7, 7, 192)    215040      activation_240[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_246 (Conv2D)             (None, 7, 7, 192)    215040      activation_245[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_247 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_23[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_238 (BatchN (None, 7, 7, 192)    576         conv2d_238[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_241 (BatchN (None, 7, 7, 192)    576         conv2d_241[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_246 (BatchN (None, 7, 7, 192)    576         conv2d_246[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_247 (BatchN (None, 7, 7, 192)    576         conv2d_247[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_238 (Activation)     (None, 7, 7, 192)    0           batch_normalization_238[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_241 (Activation)     (None, 7, 7, 192)    0           batch_normalization_241[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_246 (Activation)     (None, 7, 7, 192)    0           batch_normalization_246[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_247 (Activation)     (None, 7, 7, 192)    0           batch_normalization_247[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_238[0][0]             \n",
      "                                                                 activation_241[0][0]             \n",
      "                                                                 activation_246[0][0]             \n",
      "                                                                 activation_247[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_252 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_252 (BatchN (None, 7, 7, 192)    576         conv2d_252[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_252 (Activation)     (None, 7, 7, 192)    0           batch_normalization_252[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_253 (Conv2D)             (None, 7, 7, 192)    258048      activation_252[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_253 (BatchN (None, 7, 7, 192)    576         conv2d_253[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_253 (Activation)     (None, 7, 7, 192)    0           batch_normalization_253[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_249 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_254 (Conv2D)             (None, 7, 7, 192)    258048      activation_253[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_249 (BatchN (None, 7, 7, 192)    576         conv2d_249[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_254 (BatchN (None, 7, 7, 192)    576         conv2d_254[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_249 (Activation)     (None, 7, 7, 192)    0           batch_normalization_249[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_254 (Activation)     (None, 7, 7, 192)    0           batch_normalization_254[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_250 (Conv2D)             (None, 7, 7, 192)    258048      activation_249[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_255 (Conv2D)             (None, 7, 7, 192)    258048      activation_254[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_250 (BatchN (None, 7, 7, 192)    576         conv2d_250[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_255 (BatchN (None, 7, 7, 192)    576         conv2d_255[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_250 (Activation)     (None, 7, 7, 192)    0           batch_normalization_250[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_255 (Activation)     (None, 7, 7, 192)    0           batch_normalization_255[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_24 (AveragePo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_248 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_251 (Conv2D)             (None, 7, 7, 192)    258048      activation_250[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_256 (Conv2D)             (None, 7, 7, 192)    258048      activation_255[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_257 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_24[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_248 (BatchN (None, 7, 7, 192)    576         conv2d_248[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_251 (BatchN (None, 7, 7, 192)    576         conv2d_251[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_256 (BatchN (None, 7, 7, 192)    576         conv2d_256[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_257 (BatchN (None, 7, 7, 192)    576         conv2d_257[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_248 (Activation)     (None, 7, 7, 192)    0           batch_normalization_248[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_251 (Activation)     (None, 7, 7, 192)    0           batch_normalization_251[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_256 (Activation)     (None, 7, 7, 192)    0           batch_normalization_256[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_257 (Activation)     (None, 7, 7, 192)    0           batch_normalization_257[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_248[0][0]             \n",
      "                                                                 activation_251[0][0]             \n",
      "                                                                 activation_256[0][0]             \n",
      "                                                                 activation_257[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_260 (Conv2D)             (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_260 (BatchN (None, 7, 7, 192)    576         conv2d_260[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_260 (Activation)     (None, 7, 7, 192)    0           batch_normalization_260[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_261 (Conv2D)             (None, 7, 7, 192)    258048      activation_260[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_261 (BatchN (None, 7, 7, 192)    576         conv2d_261[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_261 (Activation)     (None, 7, 7, 192)    0           batch_normalization_261[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_258 (Conv2D)             (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_262 (Conv2D)             (None, 7, 7, 192)    258048      activation_261[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_258 (BatchN (None, 7, 7, 192)    576         conv2d_258[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_262 (BatchN (None, 7, 7, 192)    576         conv2d_262[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_258 (Activation)     (None, 7, 7, 192)    0           batch_normalization_258[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_262 (Activation)     (None, 7, 7, 192)    0           batch_normalization_262[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_259 (Conv2D)             (None, 3, 3, 320)    552960      activation_258[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_263 (Conv2D)             (None, 3, 3, 192)    331776      activation_262[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_259 (BatchN (None, 3, 3, 320)    960         conv2d_259[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_263 (BatchN (None, 3, 3, 192)    576         conv2d_263[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_259 (Activation)     (None, 3, 3, 320)    0           batch_normalization_259[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_263 (Activation)     (None, 3, 3, 192)    0           batch_normalization_263[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling2D) (None, 3, 3, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 3, 3, 1280)   0           activation_259[0][0]             \n",
      "                                                                 activation_263[0][0]             \n",
      "                                                                 max_pooling2d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_268 (Conv2D)             (None, 3, 3, 448)    573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_268 (BatchN (None, 3, 3, 448)    1344        conv2d_268[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_268 (Activation)     (None, 3, 3, 448)    0           batch_normalization_268[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_265 (Conv2D)             (None, 3, 3, 384)    491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_269 (Conv2D)             (None, 3, 3, 384)    1548288     activation_268[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_265 (BatchN (None, 3, 3, 384)    1152        conv2d_265[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_269 (BatchN (None, 3, 3, 384)    1152        conv2d_269[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_265 (Activation)     (None, 3, 3, 384)    0           batch_normalization_265[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_269 (Activation)     (None, 3, 3, 384)    0           batch_normalization_269[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_266 (Conv2D)             (None, 3, 3, 384)    442368      activation_265[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_267 (Conv2D)             (None, 3, 3, 384)    442368      activation_265[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_270 (Conv2D)             (None, 3, 3, 384)    442368      activation_269[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_271 (Conv2D)             (None, 3, 3, 384)    442368      activation_269[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_25 (AveragePo (None, 3, 3, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_264 (Conv2D)             (None, 3, 3, 320)    409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_266 (BatchN (None, 3, 3, 384)    1152        conv2d_266[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_267 (BatchN (None, 3, 3, 384)    1152        conv2d_267[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_270 (BatchN (None, 3, 3, 384)    1152        conv2d_270[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_271 (BatchN (None, 3, 3, 384)    1152        conv2d_271[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_272 (Conv2D)             (None, 3, 3, 192)    245760      average_pooling2d_25[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_264 (BatchN (None, 3, 3, 320)    960         conv2d_264[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_266 (Activation)     (None, 3, 3, 384)    0           batch_normalization_266[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_267 (Activation)     (None, 3, 3, 384)    0           batch_normalization_267[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_270 (Activation)     (None, 3, 3, 384)    0           batch_normalization_270[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_271 (Activation)     (None, 3, 3, 384)    0           batch_normalization_271[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_272 (BatchN (None, 3, 3, 192)    576         conv2d_272[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_264 (Activation)     (None, 3, 3, 320)    0           batch_normalization_264[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 3, 3, 768)    0           activation_266[0][0]             \n",
      "                                                                 activation_267[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 3, 3, 768)    0           activation_270[0][0]             \n",
      "                                                                 activation_271[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_272 (Activation)     (None, 3, 3, 192)    0           batch_normalization_272[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 3, 3, 2048)   0           activation_264[0][0]             \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate_4[0][0]              \n",
      "                                                                 activation_272[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_277 (Conv2D)             (None, 3, 3, 448)    917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_277 (BatchN (None, 3, 3, 448)    1344        conv2d_277[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_277 (Activation)     (None, 3, 3, 448)    0           batch_normalization_277[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_274 (Conv2D)             (None, 3, 3, 384)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_278 (Conv2D)             (None, 3, 3, 384)    1548288     activation_277[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_274 (BatchN (None, 3, 3, 384)    1152        conv2d_274[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_278 (BatchN (None, 3, 3, 384)    1152        conv2d_278[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_274 (Activation)     (None, 3, 3, 384)    0           batch_normalization_274[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_278 (Activation)     (None, 3, 3, 384)    0           batch_normalization_278[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_275 (Conv2D)             (None, 3, 3, 384)    442368      activation_274[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_276 (Conv2D)             (None, 3, 3, 384)    442368      activation_274[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_279 (Conv2D)             (None, 3, 3, 384)    442368      activation_278[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_280 (Conv2D)             (None, 3, 3, 384)    442368      activation_278[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_26 (AveragePo (None, 3, 3, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_273 (Conv2D)             (None, 3, 3, 320)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_275 (BatchN (None, 3, 3, 384)    1152        conv2d_275[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_276 (BatchN (None, 3, 3, 384)    1152        conv2d_276[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_279 (BatchN (None, 3, 3, 384)    1152        conv2d_279[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_280 (BatchN (None, 3, 3, 384)    1152        conv2d_280[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_281 (Conv2D)             (None, 3, 3, 192)    393216      average_pooling2d_26[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_273 (BatchN (None, 3, 3, 320)    960         conv2d_273[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_275 (Activation)     (None, 3, 3, 384)    0           batch_normalization_275[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_276 (Activation)     (None, 3, 3, 384)    0           batch_normalization_276[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_279 (Activation)     (None, 3, 3, 384)    0           batch_normalization_279[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_280 (Activation)     (None, 3, 3, 384)    0           batch_normalization_280[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_281 (BatchN (None, 3, 3, 192)    576         conv2d_281[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_273 (Activation)     (None, 3, 3, 320)    0           batch_normalization_273[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_275[0][0]             \n",
      "                                                                 activation_276[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 3, 3, 768)    0           activation_279[0][0]             \n",
      "                                                                 activation_280[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_281 (Activation)     (None, 3, 3, 192)    0           batch_normalization_281[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_273[0][0]             \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_5[0][0]              \n",
      "                                                                 activation_281[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 21,802,784\n",
      "Trainable params: 0\n",
      "Non-trainable params: 21,802,784\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "path_inception = f\"{getcwd()}/../tmp2/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n",
    "\n",
    "# Import the inception model  \n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "\n",
    "# Create an instance of the inception model from the local pre-trained weights\n",
    "local_weights_file = path_inception\n",
    "\n",
    "pre_trained_model = InceptionV3(\n",
    "    # Your Code Here\n",
    "    input_shape=(150, 150, 3),\n",
    "    include_top=False,\n",
    "    weights=None\n",
    ")\n",
    "\n",
    "pre_trained_model.load_weights(local_weights_file)\n",
    "\n",
    "# Make all the layers in the pre-trained model non-trainable\n",
    "for layer in pre_trained_model.layers:\n",
    "    # Your Code Here\n",
    "    layer.trainable = False\n",
    "  \n",
    "# Print the model summary\n",
    "pre_trained_model.summary()\n",
    "\n",
    "# Expected Output is extremely large, but should end with:\n",
    "\n",
    "#batch_normalization_v1_281 (Bat (None, 3, 3, 192)    576         conv2d_281[0][0]                 \n",
    "#__________________________________________________________________________________________________\n",
    "#activation_273 (Activation)     (None, 3, 3, 320)    0           batch_normalization_v1_273[0][0] \n",
    "#__________________________________________________________________________________________________\n",
    "#mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_275[0][0]             \n",
    "#                                                                 activation_276[0][0]             \n",
    "#__________________________________________________________________________________________________\n",
    "#concatenate_5 (Concatenate)     (None, 3, 3, 768)    0           activation_279[0][0]             \n",
    "#                                                                 activation_280[0][0]             \n",
    "#__________________________________________________________________________________________________\n",
    "#activation_281 (Activation)     (None, 3, 3, 192)    0           batch_normalization_v1_281[0][0] \n",
    "#__________________________________________________________________________________________________\n",
    "#mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_273[0][0]             \n",
    "#                                                                 mixed9_1[0][0]                   \n",
    "#                                                                 concatenate_5[0][0]              \n",
    "#                                                                 activation_281[0][0]             \n",
    "#==================================================================================================\n",
    "#Total params: 21,802,784\n",
    "#Trainable params: 0\n",
    "#Non-trainable params: 21,802,784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CFsUlwdfs_wg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last layer output shape:  (None, 7, 7, 768)\n"
     ]
    }
   ],
   "source": [
    "last_layer = pre_trained_model.get_layer('mixed7') # Your Code Here\n",
    "print('last layer output shape: ', last_layer.output_shape)\n",
    "last_output = last_layer.output # Your Code Here\n",
    "\n",
    "# Expected Output:\n",
    "# ('last layer output shape: ', (None, 7, 7, 768))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-bsWZWp5oMq9"
   },
   "outputs": [],
   "source": [
    "# Define a Callback class that stops training once accuracy reaches 97.0%\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs={}):\n",
    "    if(logs.get('accuracy')>0.97):\n",
    "      print(\"\\nReached 97.0% accuracy so cancelling training!\")\n",
    "      self.model.stop_training = True\n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BMXb913pbvFg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_188 (Conv2D)             (None, 74, 74, 32)   864         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_188 (BatchN (None, 74, 74, 32)   96          conv2d_188[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_188 (Activation)     (None, 74, 74, 32)   0           batch_normalization_188[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_189 (Conv2D)             (None, 72, 72, 32)   9216        activation_188[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_189 (BatchN (None, 72, 72, 32)   96          conv2d_189[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_189 (Activation)     (None, 72, 72, 32)   0           batch_normalization_189[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_190 (Conv2D)             (None, 72, 72, 64)   18432       activation_189[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_190 (BatchN (None, 72, 72, 64)   192         conv2d_190[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_190 (Activation)     (None, 72, 72, 64)   0           batch_normalization_190[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 35, 35, 64)   0           activation_190[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_191 (Conv2D)             (None, 35, 35, 80)   5120        max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_191 (BatchN (None, 35, 35, 80)   240         conv2d_191[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_191 (Activation)     (None, 35, 35, 80)   0           batch_normalization_191[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_192 (Conv2D)             (None, 33, 33, 192)  138240      activation_191[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_192 (BatchN (None, 33, 33, 192)  576         conv2d_192[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_192 (Activation)     (None, 33, 33, 192)  0           batch_normalization_192[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_192[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_196 (Conv2D)             (None, 16, 16, 64)   12288       max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_196 (BatchN (None, 16, 16, 64)   192         conv2d_196[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_196 (Activation)     (None, 16, 16, 64)   0           batch_normalization_196[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_194 (Conv2D)             (None, 16, 16, 48)   9216        max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_197 (Conv2D)             (None, 16, 16, 96)   55296       activation_196[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_194 (BatchN (None, 16, 16, 48)   144         conv2d_194[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_197 (BatchN (None, 16, 16, 96)   288         conv2d_197[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_194 (Activation)     (None, 16, 16, 48)   0           batch_normalization_194[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_197 (Activation)     (None, 16, 16, 96)   0           batch_normalization_197[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_18 (AveragePo (None, 16, 16, 192)  0           max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_193 (Conv2D)             (None, 16, 16, 64)   12288       max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_195 (Conv2D)             (None, 16, 16, 64)   76800       activation_194[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_198 (Conv2D)             (None, 16, 16, 96)   82944       activation_197[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_199 (Conv2D)             (None, 16, 16, 32)   6144        average_pooling2d_18[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_193 (BatchN (None, 16, 16, 64)   192         conv2d_193[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_195 (BatchN (None, 16, 16, 64)   192         conv2d_195[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_198 (BatchN (None, 16, 16, 96)   288         conv2d_198[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_199 (BatchN (None, 16, 16, 32)   96          conv2d_199[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_193 (Activation)     (None, 16, 16, 64)   0           batch_normalization_193[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_195 (Activation)     (None, 16, 16, 64)   0           batch_normalization_195[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_198 (Activation)     (None, 16, 16, 96)   0           batch_normalization_198[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_199 (Activation)     (None, 16, 16, 32)   0           batch_normalization_199[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_193[0][0]             \n",
      "                                                                 activation_195[0][0]             \n",
      "                                                                 activation_198[0][0]             \n",
      "                                                                 activation_199[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_203 (Conv2D)             (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_203 (BatchN (None, 16, 16, 64)   192         conv2d_203[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_203 (Activation)     (None, 16, 16, 64)   0           batch_normalization_203[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_201 (Conv2D)             (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_204 (Conv2D)             (None, 16, 16, 96)   55296       activation_203[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_201 (BatchN (None, 16, 16, 48)   144         conv2d_201[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_204 (BatchN (None, 16, 16, 96)   288         conv2d_204[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_201 (Activation)     (None, 16, 16, 48)   0           batch_normalization_201[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_204 (Activation)     (None, 16, 16, 96)   0           batch_normalization_204[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_19 (AveragePo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_200 (Conv2D)             (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_202 (Conv2D)             (None, 16, 16, 64)   76800       activation_201[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_205 (Conv2D)             (None, 16, 16, 96)   82944       activation_204[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_206 (Conv2D)             (None, 16, 16, 64)   16384       average_pooling2d_19[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_200 (BatchN (None, 16, 16, 64)   192         conv2d_200[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_202 (BatchN (None, 16, 16, 64)   192         conv2d_202[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_205 (BatchN (None, 16, 16, 96)   288         conv2d_205[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_206 (BatchN (None, 16, 16, 64)   192         conv2d_206[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_200 (Activation)     (None, 16, 16, 64)   0           batch_normalization_200[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_202 (Activation)     (None, 16, 16, 64)   0           batch_normalization_202[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_205 (Activation)     (None, 16, 16, 96)   0           batch_normalization_205[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_206 (Activation)     (None, 16, 16, 64)   0           batch_normalization_206[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_200[0][0]             \n",
      "                                                                 activation_202[0][0]             \n",
      "                                                                 activation_205[0][0]             \n",
      "                                                                 activation_206[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_210 (Conv2D)             (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_210 (BatchN (None, 16, 16, 64)   192         conv2d_210[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_210 (Activation)     (None, 16, 16, 64)   0           batch_normalization_210[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_208 (Conv2D)             (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_211 (Conv2D)             (None, 16, 16, 96)   55296       activation_210[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_208 (BatchN (None, 16, 16, 48)   144         conv2d_208[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_211 (BatchN (None, 16, 16, 96)   288         conv2d_211[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_208 (Activation)     (None, 16, 16, 48)   0           batch_normalization_208[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_211 (Activation)     (None, 16, 16, 96)   0           batch_normalization_211[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_20 (AveragePo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_207 (Conv2D)             (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_209 (Conv2D)             (None, 16, 16, 64)   76800       activation_208[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_212 (Conv2D)             (None, 16, 16, 96)   82944       activation_211[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_213 (Conv2D)             (None, 16, 16, 64)   18432       average_pooling2d_20[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_207 (BatchN (None, 16, 16, 64)   192         conv2d_207[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_209 (BatchN (None, 16, 16, 64)   192         conv2d_209[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_212 (BatchN (None, 16, 16, 96)   288         conv2d_212[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_213 (BatchN (None, 16, 16, 64)   192         conv2d_213[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_207 (Activation)     (None, 16, 16, 64)   0           batch_normalization_207[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_209 (Activation)     (None, 16, 16, 64)   0           batch_normalization_209[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_212 (Activation)     (None, 16, 16, 96)   0           batch_normalization_212[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_213 (Activation)     (None, 16, 16, 64)   0           batch_normalization_213[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_207[0][0]             \n",
      "                                                                 activation_209[0][0]             \n",
      "                                                                 activation_212[0][0]             \n",
      "                                                                 activation_213[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_215 (Conv2D)             (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_215 (BatchN (None, 16, 16, 64)   192         conv2d_215[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_215 (Activation)     (None, 16, 16, 64)   0           batch_normalization_215[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_216 (Conv2D)             (None, 16, 16, 96)   55296       activation_215[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_216 (BatchN (None, 16, 16, 96)   288         conv2d_216[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_216 (Activation)     (None, 16, 16, 96)   0           batch_normalization_216[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_214 (Conv2D)             (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_217 (Conv2D)             (None, 7, 7, 96)     82944       activation_216[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_214 (BatchN (None, 7, 7, 384)    1152        conv2d_214[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_217 (BatchN (None, 7, 7, 96)     288         conv2d_217[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_214 (Activation)     (None, 7, 7, 384)    0           batch_normalization_214[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_217 (Activation)     (None, 7, 7, 96)     0           batch_normalization_217[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling2D) (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_214[0][0]             \n",
      "                                                                 activation_217[0][0]             \n",
      "                                                                 max_pooling2d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_222 (Conv2D)             (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_222 (BatchN (None, 7, 7, 128)    384         conv2d_222[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_222 (Activation)     (None, 7, 7, 128)    0           batch_normalization_222[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_223 (Conv2D)             (None, 7, 7, 128)    114688      activation_222[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_223 (BatchN (None, 7, 7, 128)    384         conv2d_223[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_223 (Activation)     (None, 7, 7, 128)    0           batch_normalization_223[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_219 (Conv2D)             (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_224 (Conv2D)             (None, 7, 7, 128)    114688      activation_223[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_219 (BatchN (None, 7, 7, 128)    384         conv2d_219[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_224 (BatchN (None, 7, 7, 128)    384         conv2d_224[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_219 (Activation)     (None, 7, 7, 128)    0           batch_normalization_219[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_224 (Activation)     (None, 7, 7, 128)    0           batch_normalization_224[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_220 (Conv2D)             (None, 7, 7, 128)    114688      activation_219[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_225 (Conv2D)             (None, 7, 7, 128)    114688      activation_224[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_220 (BatchN (None, 7, 7, 128)    384         conv2d_220[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_225 (BatchN (None, 7, 7, 128)    384         conv2d_225[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_220 (Activation)     (None, 7, 7, 128)    0           batch_normalization_220[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_225 (Activation)     (None, 7, 7, 128)    0           batch_normalization_225[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_21 (AveragePo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_218 (Conv2D)             (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_221 (Conv2D)             (None, 7, 7, 192)    172032      activation_220[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_226 (Conv2D)             (None, 7, 7, 192)    172032      activation_225[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_227 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_21[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_218 (BatchN (None, 7, 7, 192)    576         conv2d_218[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_221 (BatchN (None, 7, 7, 192)    576         conv2d_221[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_226 (BatchN (None, 7, 7, 192)    576         conv2d_226[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_227 (BatchN (None, 7, 7, 192)    576         conv2d_227[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_218 (Activation)     (None, 7, 7, 192)    0           batch_normalization_218[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_221 (Activation)     (None, 7, 7, 192)    0           batch_normalization_221[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_226 (Activation)     (None, 7, 7, 192)    0           batch_normalization_226[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_227 (Activation)     (None, 7, 7, 192)    0           batch_normalization_227[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_218[0][0]             \n",
      "                                                                 activation_221[0][0]             \n",
      "                                                                 activation_226[0][0]             \n",
      "                                                                 activation_227[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_232 (Conv2D)             (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_232 (BatchN (None, 7, 7, 160)    480         conv2d_232[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_232 (Activation)     (None, 7, 7, 160)    0           batch_normalization_232[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_233 (Conv2D)             (None, 7, 7, 160)    179200      activation_232[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_233 (BatchN (None, 7, 7, 160)    480         conv2d_233[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_233 (Activation)     (None, 7, 7, 160)    0           batch_normalization_233[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_229 (Conv2D)             (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_234 (Conv2D)             (None, 7, 7, 160)    179200      activation_233[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_229 (BatchN (None, 7, 7, 160)    480         conv2d_229[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_234 (BatchN (None, 7, 7, 160)    480         conv2d_234[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_229 (Activation)     (None, 7, 7, 160)    0           batch_normalization_229[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_234 (Activation)     (None, 7, 7, 160)    0           batch_normalization_234[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_230 (Conv2D)             (None, 7, 7, 160)    179200      activation_229[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_235 (Conv2D)             (None, 7, 7, 160)    179200      activation_234[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_230 (BatchN (None, 7, 7, 160)    480         conv2d_230[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_235 (BatchN (None, 7, 7, 160)    480         conv2d_235[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_230 (Activation)     (None, 7, 7, 160)    0           batch_normalization_230[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_235 (Activation)     (None, 7, 7, 160)    0           batch_normalization_235[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_22 (AveragePo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_228 (Conv2D)             (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_231 (Conv2D)             (None, 7, 7, 192)    215040      activation_230[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_236 (Conv2D)             (None, 7, 7, 192)    215040      activation_235[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_237 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_22[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_228 (BatchN (None, 7, 7, 192)    576         conv2d_228[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_231 (BatchN (None, 7, 7, 192)    576         conv2d_231[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_236 (BatchN (None, 7, 7, 192)    576         conv2d_236[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_237 (BatchN (None, 7, 7, 192)    576         conv2d_237[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_228 (Activation)     (None, 7, 7, 192)    0           batch_normalization_228[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_231 (Activation)     (None, 7, 7, 192)    0           batch_normalization_231[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_236 (Activation)     (None, 7, 7, 192)    0           batch_normalization_236[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_237 (Activation)     (None, 7, 7, 192)    0           batch_normalization_237[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_228[0][0]             \n",
      "                                                                 activation_231[0][0]             \n",
      "                                                                 activation_236[0][0]             \n",
      "                                                                 activation_237[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_242 (Conv2D)             (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_242 (BatchN (None, 7, 7, 160)    480         conv2d_242[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_242 (Activation)     (None, 7, 7, 160)    0           batch_normalization_242[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_243 (Conv2D)             (None, 7, 7, 160)    179200      activation_242[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_243 (BatchN (None, 7, 7, 160)    480         conv2d_243[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_243 (Activation)     (None, 7, 7, 160)    0           batch_normalization_243[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_239 (Conv2D)             (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_244 (Conv2D)             (None, 7, 7, 160)    179200      activation_243[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_239 (BatchN (None, 7, 7, 160)    480         conv2d_239[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_244 (BatchN (None, 7, 7, 160)    480         conv2d_244[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_239 (Activation)     (None, 7, 7, 160)    0           batch_normalization_239[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_244 (Activation)     (None, 7, 7, 160)    0           batch_normalization_244[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_240 (Conv2D)             (None, 7, 7, 160)    179200      activation_239[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_245 (Conv2D)             (None, 7, 7, 160)    179200      activation_244[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_240 (BatchN (None, 7, 7, 160)    480         conv2d_240[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_245 (BatchN (None, 7, 7, 160)    480         conv2d_245[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_240 (Activation)     (None, 7, 7, 160)    0           batch_normalization_240[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_245 (Activation)     (None, 7, 7, 160)    0           batch_normalization_245[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_23 (AveragePo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_238 (Conv2D)             (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_241 (Conv2D)             (None, 7, 7, 192)    215040      activation_240[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_246 (Conv2D)             (None, 7, 7, 192)    215040      activation_245[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_247 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_23[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_238 (BatchN (None, 7, 7, 192)    576         conv2d_238[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_241 (BatchN (None, 7, 7, 192)    576         conv2d_241[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_246 (BatchN (None, 7, 7, 192)    576         conv2d_246[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_247 (BatchN (None, 7, 7, 192)    576         conv2d_247[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_238 (Activation)     (None, 7, 7, 192)    0           batch_normalization_238[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_241 (Activation)     (None, 7, 7, 192)    0           batch_normalization_241[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_246 (Activation)     (None, 7, 7, 192)    0           batch_normalization_246[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_247 (Activation)     (None, 7, 7, 192)    0           batch_normalization_247[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_238[0][0]             \n",
      "                                                                 activation_241[0][0]             \n",
      "                                                                 activation_246[0][0]             \n",
      "                                                                 activation_247[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_252 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_252 (BatchN (None, 7, 7, 192)    576         conv2d_252[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_252 (Activation)     (None, 7, 7, 192)    0           batch_normalization_252[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_253 (Conv2D)             (None, 7, 7, 192)    258048      activation_252[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_253 (BatchN (None, 7, 7, 192)    576         conv2d_253[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_253 (Activation)     (None, 7, 7, 192)    0           batch_normalization_253[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_249 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_254 (Conv2D)             (None, 7, 7, 192)    258048      activation_253[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_249 (BatchN (None, 7, 7, 192)    576         conv2d_249[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_254 (BatchN (None, 7, 7, 192)    576         conv2d_254[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_249 (Activation)     (None, 7, 7, 192)    0           batch_normalization_249[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_254 (Activation)     (None, 7, 7, 192)    0           batch_normalization_254[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_250 (Conv2D)             (None, 7, 7, 192)    258048      activation_249[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_255 (Conv2D)             (None, 7, 7, 192)    258048      activation_254[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_250 (BatchN (None, 7, 7, 192)    576         conv2d_250[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_255 (BatchN (None, 7, 7, 192)    576         conv2d_255[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_250 (Activation)     (None, 7, 7, 192)    0           batch_normalization_250[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_255 (Activation)     (None, 7, 7, 192)    0           batch_normalization_255[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_24 (AveragePo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_248 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_251 (Conv2D)             (None, 7, 7, 192)    258048      activation_250[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_256 (Conv2D)             (None, 7, 7, 192)    258048      activation_255[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_257 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_24[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_248 (BatchN (None, 7, 7, 192)    576         conv2d_248[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_251 (BatchN (None, 7, 7, 192)    576         conv2d_251[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_256 (BatchN (None, 7, 7, 192)    576         conv2d_256[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_257 (BatchN (None, 7, 7, 192)    576         conv2d_257[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_248 (Activation)     (None, 7, 7, 192)    0           batch_normalization_248[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_251 (Activation)     (None, 7, 7, 192)    0           batch_normalization_251[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_256 (Activation)     (None, 7, 7, 192)    0           batch_normalization_256[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_257 (Activation)     (None, 7, 7, 192)    0           batch_normalization_257[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_248[0][0]             \n",
      "                                                                 activation_251[0][0]             \n",
      "                                                                 activation_256[0][0]             \n",
      "                                                                 activation_257[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 37632)        0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1024)         38536192    flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 1024)         0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 1)            1025        dropout_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 47,512,481\n",
      "Trainable params: 38,537,217\n",
      "Non-trainable params: 8,975,264\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "# Flatten the output layer to 1 dimension\n",
    "x = layers.Flatten()(last_output)\n",
    "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
    "x = layers.Dense(1024, activation='relu')(x) # Your Code Here\n",
    "# Add a dropout rate of 0.2\n",
    "x = layers.Dropout(0.2)(x) # Your Code Here\n",
    "# Add a final sigmoid layer for classification\n",
    "x = layers.Dense(1, activation='sigmoid')(x) # Your Code Here\n",
    "\n",
    "model = Model(pre_trained_model.input, x) # Your Code Here\n",
    "\n",
    "model.compile(optimizer = RMSprop(lr=0.0001),\n",
    "              loss = 'binary_crossentropy', # Your Code Here, \n",
    "              metrics = ['accuracy']) # Your Code Here\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Expected output will be large. Last few lines should be:\n",
    "\n",
    "# mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_248[0][0]             \n",
    "#                                                                  activation_251[0][0]             \n",
    "#                                                                  activation_256[0][0]             \n",
    "#                                                                  activation_257[0][0]             \n",
    "# __________________________________________________________________________________________________\n",
    "# flatten_4 (Flatten)             (None, 37632)        0           mixed7[0][0]                     \n",
    "# __________________________________________________________________________________________________\n",
    "# dense_8 (Dense)                 (None, 1024)         38536192    flatten_4[0][0]                  \n",
    "# __________________________________________________________________________________________________\n",
    "# dropout_4 (Dropout)             (None, 1024)         0           dense_8[0][0]                    \n",
    "# __________________________________________________________________________________________________\n",
    "# dense_9 (Dense)                 (None, 1)            1025        dropout_4[0][0]                  \n",
    "# ==================================================================================================\n",
    "# Total params: 47,512,481\n",
    "# Trainable params: 38,537,217\n",
    "# Non-trainable params: 8,975,264\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HrnL_IQ8knWA"
   },
   "outputs": [],
   "source": [
    "# Get the Horse or Human dataset\n",
    "path_horse_or_human = f\"{getcwd()}/../tmp2/horse-or-human.zip\"\n",
    "# Get the Horse or Human Validation dataset\n",
    "path_validation_horse_or_human = f\"{getcwd()}/../tmp2/validation-horse-or-human.zip\"\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import os\n",
    "import zipfile\n",
    "import shutil\n",
    "\n",
    "shutil.rmtree('/tmp')\n",
    "local_zip = path_horse_or_human\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall('/tmp/training')\n",
    "zip_ref.close()\n",
    "\n",
    "local_zip = path_validation_horse_or_human\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall('/tmp/validation')\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y9okX7_ovskI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "527\n",
      "128\n",
      "128\n"
     ]
    }
   ],
   "source": [
    "# Define our example directories and files\n",
    "train_dir = '/tmp/training'\n",
    "validation_dir = '/tmp/validation'\n",
    "\n",
    "train_horses_dir = '/tmp/training/horses' # Your Code Here\n",
    "train_humans_dir = '/tmp/training/humans' # Your Code Here\n",
    "validation_horses_dir = '/tmp/validation/horses' # Your Code Here\n",
    "validation_humans_dir = '/tmp/validation/humans' # Your Code Here\n",
    "\n",
    "train_horses_fnames = os.listdir(train_horses_dir) # Your Code Here\n",
    "train_humans_fnames = os.listdir(train_humans_dir) # Your Code Here\n",
    "validation_horses_fnames = os.listdir(validation_horses_dir) # Your Code Here\n",
    "validation_humans_fnames = os.listdir(validation_humans_dir) # Your Code Here\n",
    "\n",
    "print(len(train_horses_fnames)) # Your Code Here\n",
    "print(len(train_humans_fnames)) # Your Code Here\n",
    "print(len(validation_horses_fnames)) # Your Code Here\n",
    "print(len(validation_humans_fnames)) # Your Code Here\n",
    "\n",
    "# Expected Output:\n",
    "# 500\n",
    "# 527\n",
    "# 128\n",
    "# 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O4s8HckqGlnb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1027 images belonging to 2 classes.\n",
      "Found 256 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Add our data-augmentation parameters to ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(\n",
    "    # Your Code Here\n",
    "    rescale = 1./255,\n",
    "    rotation_range = 40,\n",
    "    width_shift_range = 0.2,\n",
    "    height_shift_range = 0.2,\n",
    "    shear_range = 0.2,\n",
    "    zoom_range = 0.2,\n",
    "    horizontal_flip = True\n",
    ")\n",
    "\n",
    "# Note that the validation data should not be augmented!\n",
    "test_datagen = ImageDataGenerator(rescale=1./255) # Your Code Here\n",
    "\n",
    "# Flow training images in batches of 20 using train_datagen generator\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    # Your Code Here\n",
    "    train_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=20,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "# Flow validation images in batches of 20 using test_datagen generator\n",
    "validation_generator =  test_datagen.flow_from_directory(\n",
    "    # Your Code Here\n",
    "    validation_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=20,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "# Expected Output:\n",
    "# Found 1027 images belonging to 2 classes.\n",
    "# Found 256 images belonging to 2 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Blhq2MAUeyGA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "52/52 - 42s - loss: 0.2966 - accuracy: 0.8919 - val_loss: 0.0112 - val_accuracy: 0.9961\n",
      "Epoch 2/3\n",
      "52/52 - 38s - loss: 0.1051 - accuracy: 0.9611 - val_loss: 0.1831 - val_accuracy: 0.9688\n",
      "Epoch 3/3\n",
      "\n",
      "Reached 97.0% accuracy so cancelling training!\n",
      "52/52 - 39s - loss: 0.0544 - accuracy: 0.9844 - val_loss: 0.1246 - val_accuracy: 0.9648\n"
     ]
    }
   ],
   "source": [
    "# Run this and see how many epochs it should take before the callback\n",
    "# fires, and stops training at 97% accuracy\n",
    "\n",
    "callbacks = myCallback() # Your Code Here\n",
    "history = model.fit_generator(\n",
    "    # Your Code Here (set epochs = 3)\n",
    "    train_generator,\n",
    "    validation_data=validation_generator,\n",
    "    epochs=3,\n",
    "    verbose=2,\n",
    "    callbacks=[callbacks]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C2Fp6Se9rKuL"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend(loc=0)\n",
    "plt.figure()\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission Instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now click the 'Submit Assignment' button above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# When you're done or would like to take a break, please run the two cells below to save your work and close the Notebook. This will free up resources for your fellow learners. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "<!-- Save the notebook -->\n",
    "IPython.notebook.save_checkpoint();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "IPython.notebook.session.delete();\n",
    "window.onbeforeunload = null\n",
    "setTimeout(function() { window.close(); }, 1000);"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Exercise 7 - Question.ipynb",
   "provenance": []
  },
  "coursera": {
   "course_slug": "convolutional-neural-networks-tensorflow",
   "graded_item_id": "csg1x",
   "launcher_item_id": "GpKYz"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
